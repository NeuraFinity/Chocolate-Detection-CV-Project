{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432c9205-d6d7-4de8-a226-0abb86a3063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mysterious Soul\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 531 images belonging to 2 classes.\n",
      "Found 177 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Mysterious Soul\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Mysterious Soul\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Mysterious Soul\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Mysterious Soul\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Mysterious Soul\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "17/17 [==============================] - 73s 4s/step - loss: 0.5829 - accuracy: 0.7213 - val_loss: 0.5237 - val_accuracy: 0.7684\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 71s 4s/step - loss: 0.5684 - accuracy: 0.7213 - val_loss: 0.5113 - val_accuracy: 0.7684\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 71s 4s/step - loss: 0.5544 - accuracy: 0.7213 - val_loss: 0.5301 - val_accuracy: 0.7684\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 71s 4s/step - loss: 0.5543 - accuracy: 0.7213 - val_loss: 0.5027 - val_accuracy: 0.7684\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 71s 4s/step - loss: 0.5426 - accuracy: 0.7232 - val_loss: 0.5129 - val_accuracy: 0.7684\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.5347 - accuracy: 0.7213 - val_loss: 0.5044 - val_accuracy: 0.7684\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.5307 - accuracy: 0.7232 - val_loss: 0.5093 - val_accuracy: 0.7684\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 77s 5s/step - loss: 0.5306 - accuracy: 0.7345 - val_loss: 0.4950 - val_accuracy: 0.7684\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.5321 - accuracy: 0.7194 - val_loss: 0.5024 - val_accuracy: 0.7684\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 72s 4s/step - loss: 0.5228 - accuracy: 0.7213 - val_loss: 0.4930 - val_accuracy: 0.7684\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.4930 - accuracy: 0.7684\n",
      "Test accuracy: 0.7683615684509277\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data paths\n",
    "train_data_dir = 'NewData/Train'\n",
    "valid_data_dir = 'NewData/Test'\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_data_dir, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Model selection (Using a pre-trained ResNet50)\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training (fine-tuning only the top layers)\n",
    "model.fit(train_generator, epochs=10, validation_data=valid_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(valid_generator)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d6f4e-d772-4728-8cac-56d3e50a5e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06923336-c3f9-4700-ad99-3c6f57f698a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 images belonging to 2 classes.\n",
      "Found 177 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 72s 6s/step - loss: 0.6303 - accuracy: 0.6358 - val_loss: 0.6194 - val_accuracy: 0.6836\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 64s 6s/step - loss: 0.5660 - accuracy: 0.6852 - val_loss: 0.5459 - val_accuracy: 0.7684\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 72s 7s/step - loss: 0.4196 - accuracy: 0.7994 - val_loss: 0.5062 - val_accuracy: 0.7684\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 68s 6s/step - loss: 0.4969 - accuracy: 0.7562 - val_loss: 0.5495 - val_accuracy: 0.7684\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 67s 6s/step - loss: 0.5020 - accuracy: 0.7469 - val_loss: 0.5618 - val_accuracy: 0.7684\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 74s 6s/step - loss: 0.5097 - accuracy: 0.7469 - val_loss: 0.5027 - val_accuracy: 0.7684\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 67s 6s/step - loss: 0.4399 - accuracy: 0.7901 - val_loss: 0.5659 - val_accuracy: 0.7684\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 68s 6s/step - loss: 0.3824 - accuracy: 0.8086 - val_loss: 0.8931 - val_accuracy: 0.7684\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.3339 - accuracy: 0.8611 - val_loss: 1.0853 - val_accuracy: 0.7684\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 73s 7s/step - loss: 0.3449 - accuracy: 0.8519 - val_loss: 0.7627 - val_accuracy: 0.7684\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.7627 - accuracy: 0.7684\n",
      "Test accuracy: 0.7683615684509277\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data paths\n",
    "train_data_dir = 'NewData/Train'\n",
    "valid_data_dir = 'NewData/Test'\n",
    "\n",
    "# Data preprocessing\n",
    "# Create an instance of the ImageDataGenerator class with the desired transformations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Rescale the pixel values to [0,1] range\n",
    "    rotation_range=40, # Randomly rotate the images by 40 degrees\n",
    "    width_shift_range=0.2, # Randomly shift the images horizontally by 20% of the width\n",
    "    height_shift_range=0.2, # Randomly shift the images vertically by 20% of the height\n",
    "    shear_range=0.2, # Randomly shear the images by 20 degrees\n",
    "    zoom_range=0.2, # Randomly zoom the images by 20%\n",
    "    horizontal_flip=True, # Randomly flip the images horizontally\n",
    "    fill_mode='nearest' # Fill the missing pixels with the nearest filled value\n",
    ")\n",
    "\n",
    "# Create another instance of the ImageDataGenerator class for the validation data\n",
    "# Only rescale the pixel values, no other transformations\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create an iterator that can load the images from the directory and apply the transformations\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, # The directory where the training images are stored\n",
    "    target_size=(224, 224), # The target size of the images, 224x224 pixels\n",
    "    batch_size=32, # The batch size, 32 images per batch\n",
    "    class_mode='binary' # The class mode, binary labels\n",
    ")\n",
    "\n",
    "# Create another iterator for the validation data\n",
    "# No transformations, only rescaling\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir, # The directory where the validation images are stored\n",
    "    target_size=(224, 224), # The target size of the images, 224x224 pixels\n",
    "    batch_size=32, # The batch size, 32 images per batch\n",
    "    class_mode='binary' # The class mode, binary labels\n",
    ")\n",
    "\n",
    "# Model selection (Using a pre-trained ResNet50)\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Unfreeze the last convolutional block of the base model\n",
    "for layer in base_model.layers:\n",
    "    # Check if the layer name starts with 'conv5'\n",
    "    if layer.name.startswith('conv5'):\n",
    "        # Set the layer to be trainable\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        # Keep the rest of the layers frozen\n",
    "        layer.trainable = False\n",
    "\n",
    "# Model compilation\n",
    "# Use a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training (fine-tuning the unfrozen layers)\n",
    "# Use the train_generator and the valid_generator as the data sources\n",
    "model.fit(train_generator, epochs=10, validation_data=valid_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(valid_generator)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cdf18ca-fc6c-4ca4-a0b0-edc7d4b08bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mysterious Soul\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('trained_model_acc_87.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e989eb9-f790-4056-a273-93dbced07d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "The image is dairymilk with a probability of 0.9327480792999268.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load the model\n",
    "model = load_model('trained_model_acc_87.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = load_img('NewData/Valid/DairyMilk/cadbury-9-_jpg.rf.b2451da6e2debc82fb4f306f40f82580.jpg', target_size=(224, 224)) # Load the image and resize it\n",
    "img = img_to_array(img) # Convert the image to a numpy array\n",
    "img = img / 255. # Rescale the pixel values to [0, 1] range\n",
    "img = np.expand_dims(img, axis=0) # Add a batch dimension\n",
    "\n",
    "# Predict the label of the image\n",
    "prob = model.predict(img) # Get the probability of the image belonging to the dairymilk class\n",
    "prob = np.squeeze(prob) # Remove the singleton dimensions\n",
    "label = np.round(prob) # Round the probability to the nearest integer\n",
    "\n",
    "# Print the result\n",
    "if label == 1:\n",
    "    print(f'The image is dairymilk with a probability of {prob}.')\n",
    "else:\n",
    "    print(f'The image is not dairymilk with a probability of {1 - prob}.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
